{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65820fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2089cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_prediction(pred):\n",
    "    label_dict = {'Multiplication': 0, 'Subtraction': 1, 'Addition': 2, 'Division': 3}    \n",
    "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
    "    y_pred = [k for k, v in label_dict.items() if pred_flat[0] == v]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57224c",
   "metadata": {},
   "source": [
    "# Clean Input and make into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb71590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "\n",
    "    return: modified initial string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub('', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57485d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create df from single input (SINGLE ROW)\n",
    "# user_input = 'In the fridge, there are 4 stacks of chocolate puddings, 7 stacks of brownies and 5 stacks of pasta salad. How many stacks of dessert are there?'\n",
    "\n",
    "# df = pd.DataFrame([[user_input, '0']], columns=['UserInput', 'label'])\n",
    "\n",
    "# df = df.astype({'label':'int'})\n",
    "# df = df.astype({'UserInput':'str'})\n",
    "\n",
    "# # columns of dataframe\n",
    "# print(list(df.columns))\n",
    "# df.head()\n",
    "\n",
    "# #storing the punctuation free text\n",
    "# df['Clean']= df['UserInput'].apply(lambda x:clean_text(x))\n",
    "# df['Clean'][0]\n",
    "# df.label.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97e83a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Type</th>\n",
       "      <th>Clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>in the fridge there are stacks of chocolate pu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     Type                                              Clean  \\\n",
       "0         NaN  Unknown  in the fridge there are stacks of chocolate pu...   \n",
       "\n",
       "   label  \n",
       "0      3  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined.csv')\n",
    "df.drop(df.index,inplace=True) \n",
    "df.label.dtype\n",
    "\n",
    "user_input = 'In the fridge, there are 4 stacks of chocolate puddings, 7 stacks of brownies and 5 stacks of pasta salad. How many stacks of dessert are there?'\n",
    "user_input = clean_text(user_input)\n",
    "userdf = {\"Type\": ['Unknown'],\n",
    "          \"Clean\": [user_input], \n",
    "          \"label\": [3]\n",
    "         }\n",
    "userdf = pd.DataFrame(userdf)\n",
    "\n",
    "df = pd.concat([df, userdf], ignore_index = True)\n",
    "\n",
    "df = df.tail(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "472b2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80239765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\d3583\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2300: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_pred = tokenizer.batch_encode_plus(\n",
    "    df.Clean.values,\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "093027e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_pred = encoded_data_pred['input_ids']\n",
    "attention_masks_pred = encoded_data_pred['attention_mask']\n",
    "labels_pred = torch.tensor(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d690342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pred = TensorDataset(input_ids_pred, attention_masks_pred, labels_pred)\n",
    "# dataset_pred = TensorDataset(input_ids_pred, attention_masks_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98704b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "device = 'cpu'\n",
    "dataloader_prediction = DataLoader(dataset_pred)\n",
    "#                                    sampler=SequentialSampler(dataset_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43a7da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  encode values in labels\n",
    "label_dict = {'Multiplication': 0, 'Subtraction': 1, 'Addition': 2, 'Division': 3}\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('ep2finetuned_BERT_epoch_2.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f698e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "        \n",
    "        # disable gradient calculation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "#     loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b399352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction, true_val = evaluate(dataloader_prediction)\n",
    "true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d4577b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Addition'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_prediction(prediction)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
