{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65820fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2089cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_prediction(pred):\n",
    "    label_dict = {'Multiplication': 0, 'Subtraction': 1, 'Addition': 2, 'Division': 3}    \n",
    "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
    "    y_pred = [k for k, v in label_dict.items() if pred_flat[0] == v]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57224c",
   "metadata": {},
   "source": [
    "# Clean Input and make into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb71590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "\n",
    "    return: modified initial string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub('', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57485d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create df from single input (SINGLE ROW)\n",
    "# user_input = 'In the fridge, there are 4 stacks of chocolate puddings, 7 stacks of brownies and 5 stacks of pasta salad. How many stacks of dessert are there?'\n",
    "\n",
    "# df = pd.DataFrame([[user_input, '0']], columns=['UserInput', 'label'])\n",
    "\n",
    "# df = df.astype({'label':'int'})\n",
    "# df = df.astype({'UserInput':'str'})\n",
    "\n",
    "# # columns of dataframe\n",
    "# print(list(df.columns))\n",
    "# df.head()\n",
    "\n",
    "# #storing the punctuation free text\n",
    "# df['Clean']= df['UserInput'].apply(lambda x:clean_text(x))\n",
    "# df['Clean'][0]\n",
    "# df.label.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e83a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Type</th>\n",
       "      <th>Clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>239</td>\n",
       "      <td>Subtraction</td>\n",
       "      <td>zachary did pushups in gym class today david d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         Type  \\\n",
       "1561         239  Subtraction   \n",
       "\n",
       "                                                  Clean  label  \n",
       "1561  zachary did pushups in gym class today david d...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined.csv')\n",
    "df = df.tail(1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80239765",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_pred = tokenizer.batch_encode_plus(\n",
    "    df.Clean.values,\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093027e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_pred = encoded_data_pred['input_ids']\n",
    "attention_masks_pred = encoded_data_pred['attention_mask']\n",
    "labels_pred = torch.tensor(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d690342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pred = TensorDataset(input_ids_pred, attention_masks_pred, labels_pred)\n",
    "# dataset_pred = TensorDataset(input_ids_pred, attention_masks_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98704b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "device = 'cpu'\n",
    "dataloader_prediction = DataLoader(dataset_pred)\n",
    "#                                    sampler=SequentialSampler(dataset_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  encode values in labels\n",
    "label_dict = {'Multiplication': 0, 'Subtraction': 1, 'Addition': 2, 'Division': 3}\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('ep2finetuned_BERT_epoch_2.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f698e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "        \n",
    "        # disable gradient calculation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "#     loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b399352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction, true_val = evaluate(dataloader_prediction)\n",
    "true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4577b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_prediction(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
