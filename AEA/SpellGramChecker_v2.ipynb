{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SpellGramChecker_v2.ipynb","provenance":[],"toc_visible":true,"collapsed_sections":[],"authorship_tag":"ABX9TyMCnaRvBfEe8q6sNr+EqKQ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Spell Checker v2\n","\n","- en-US, en_UK, en-IN dictionary support\n","- Corrects variants of words (real word errors) as well\n","- moving towards context based sentence correction using ngram models"],"metadata":{"id":"OK15MUoCDYI0"}},{"cell_type":"code","source":["!pip install pyenchant\n","!apt-get install enchant\n","!pip install numpy\n","!pip install nltk\n","!pip install pandas\n","!pip install wget\n","!pip install textblob"],"metadata":{"id":"WZ-eKw5Vk-6G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import enchant\n","import numpy as np\n","import csv\n","import math, collections\n","import pandas as pd\n","import re\n","import itertools\n","import nltk\n","nltk.download('punkt')\n","from nltk import tokenize\n","import nltk.data\n","import wget\n","import pandas as pd \n","from textblob import TextBlob"],"metadata":{"id":"PIFWw-1-EmkI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645261391156,"user_tz":-330,"elapsed":1439,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"4831e3e2-662e-4e04-d71b-0c5714d388be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJ-BNkcZkzcm"},"outputs":[],"source":["class Sentence_Corrector :\n","    def __init__(self, training_file, tag=\"en_US\") :\n","        self.laplaceUnigramCounts = collections.defaultdict(lambda: 0)\n","        self.laplaceBigramCounts = collections.defaultdict(lambda: 0)\n","        self.total = 0\n","        self.sentences = []\n","        self.importantKeywords = set()\n","        self.tag = tag\n","        self.d = enchant.Dict(tag)\n","        self.tokenize_file(training_file)\n","        self.train()\n","\n","    def tokenize_file(self, file) :\n","        # \"\"\"\n","        #   Read the file, tokenize and build a list of sentences\n","        # \"\"\"\n","        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n","        f = open(file)\n","        content = f.read()\n","        for sentence in tokenizer.tokenize(content):\n","            sentence_clean = [i.lower() for i in re.split('[^a-zA-Z]+', sentence) if i]\n","            self.sentences.append(sentence_clean)\n","\n","\n","    def train(self):\n","        # \"\"\"\n","        #   Train unigram and bigram\n","        # \"\"\"\n","        for sentence in self.sentences:\n","            sentence.insert(0, '<s>')\n","            sentence.append('</s>')\n","            for i in range(len(sentence) - 1):\n","                token1 = sentence[i]\n","                token2 = sentence[i + 1]\n","                self.laplaceUnigramCounts[token1] += 1\n","                self.laplaceBigramCounts[(token1, token2)] += 1\n","                self.total += 1\n","            self.total += 1\n","            self.laplaceUnigramCounts[sentence[-1]] += 1\n","\n","\n","    def candidate_word(self, word):\n","        # \"\"\"\n","        # Generate similar word for a given word\n","        # \"\"\"\n","        suggests = []\n","        for candidate in self.importantKeywords:\n","            if candidate.startswith(word):\n","                suggests.append(candidate)\n","        suggests.append(word)\n","\n","        if len(suggests) == 1:\n","            suggests = self.d.suggest(word)\n","            suggests = [suggest.lower() for suggest in suggests][:4]\n","            suggests.append(word)\n","            suggests = list(set(suggests))\n","\n","        return suggests, len(suggests)\n","\n","    def candidate_sentence(self, sentence):\n","        # \"\"\"\n","        # Takes one sentence, and return all the possible sentences, and also return a dictionary of word : suggested number of words\n","        # \"\"\"\n","        candidate_sentences = []\n","        words_count = {}\n","        for word in sentence:\n","            candidate_sentences.append(self.candidate_word(word)[0])\n","            words_count[word] = self.candidate_word(word)[1]\n","\n","        candidate_sentences = list(itertools.product(*candidate_sentences))\n","        return candidate_sentences, words_count\n","\n","    def correction_score(self, words_count, old_sentence, new_sentence) :\n","        # \"\"\"\n","        #   Take a old sentence and a new sentence, for each words in the new sentence, if it's same as the orginal sentence, assign 0.95 prob\n","        #   If it's not same as original sentence, give 0.05 / (count(similarword) - 1)\n","        # \"\"\"\n","        score = 1\n","        for i in range(len(new_sentence)) :\n","            if new_sentence[i] in words_count :\n","                score *= 0.95\n","            else :\n","                score *= (0.05 / (words_count[old_sentence[i]] - 1))\n","        return math.log(score)\n","\n","    def score(self, sentence):\n","        # \"\"\"\n","        #     Takes a list of strings as argument and returns the log-probability of the\n","        #     sentence using the stupid backoff language model.\n","        #     Use laplace smoothing to avoid new words with 0 probability\n","        # \"\"\"\n","        score = 0.0\n","        for i in range(len(sentence) - 1):\n","            if self.laplaceBigramCounts[(sentence[i],sentence[i + 1])] > 0:\n","                score += math.log(self.laplaceBigramCounts[(sentence[i],sentence[i + 1])])\n","                score -= math.log(self.laplaceUnigramCounts[sentence[i]])\n","            else:\n","                score += (math.log(self.laplaceUnigramCounts[sentence[i + 1]] + 1) + math.log(0.4))\n","                score -= math.log(self.total + len(self.laplaceUnigramCounts))\n","        return score\n","\n","    def return_best_sentence(self, old_sentence) :\n","        # \"\"\"\n","        #   Generate all candiate sentences and\n","        #   Calculate the prob of each one and return the one with highest probability\n","        #   Probability involves two part 1. correct probability and 2. language model prob\n","        #   correct prob : p(c | w)\n","        #   language model prob : use stupid backoff algorithm\n","        # \"\"\"\n","        bestScore = float('-inf')\n","        bestSentence = []\n","        old_sentence = [word.lower() for word in old_sentence.split()]\n","        sentences, word_count = self.candidate_sentence(old_sentence)\n","        for new_sentence in sentences:\n","            new_sentence = list(new_sentence)\n","            score = self.correction_score(word_count, new_sentence, old_sentence)\n","            new_sentence.insert(0, '<s>')\n","            new_sentence.append('</s>')\n","            score += self.score(new_sentence)\n","            if score >= bestScore:\n","                bestScore = score\n","                bestSentence = new_sentence\n","        bestSentence = ' '.join(bestSentence[1:-1])\n","        return bestSentence, bestScore"]},{"cell_type":"code","source":["import os\n","if not os.path.exists('./big.txt'):\n","  wget.download('http://norvig.com/big.txt', './big.txt')\n","\n","corrector = Sentence_Corrector('./big.txt', tag='en_IN')"],"metadata":{"id":"pwAnOMgkmpOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Outputs\n","- Output for variant dicts like US-English, UK-English, IN-English\n","- Let us compare the outputs of our spell corrector based on it's initialised dictionaries (en_UK / en_US / en_IN)"],"metadata":{"id":"Euo9Y5ZfFQPe"}},{"cell_type":"code","source":["corrector_in = Sentence_Corrector('./big.txt', tag='en_IN')\n","corrector_uk = Sentence_Corrector('./big.txt', tag='en_UK')\n","corrector_us = Sentence_Corrector('./big.txt', tag='en_US')"],"metadata":{"id":"zN0SgQOPII7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sent = \"this is the wron spallin of the word\"\n","d = collections.defaultdict(list)\n","correctors = [corrector_in, corrector_uk, corrector_us]\n","for corr in correctors:\n","  d['tag'].append(corr.tag)\n","  d['correction'].append(corr.return_best_sentence(sent)[0])\n","\n","print(\"incorrect sentence: \", sent)\n","pd.DataFrame(d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"OGC18K11FcGr","executionInfo":{"status":"ok","timestamp":1645261891165,"user_tz":-330,"elapsed":5591,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"5bde2e18-e047-4671-b024-9d71d3e3f403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["incorrect sentence:  this is the wron spallin of the word\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5ad45bc5-0b3e-4eba-84bf-3c01dfbdc885\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tag</th>\n","      <th>correction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>en_IN</td>\n","      <td>this is the wrong spelling of the world</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>en_UK</td>\n","      <td>this is the wrong spelling of the world</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>en_US</td>\n","      <td>this is the wrong spinal of the world</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ad45bc5-0b3e-4eba-84bf-3c01dfbdc885')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5ad45bc5-0b3e-4eba-84bf-3c01dfbdc885 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5ad45bc5-0b3e-4eba-84bf-3c01dfbdc885');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     tag                               correction\n","0  en_IN  this is the wrong spelling of the world\n","1  en_UK  this is the wrong spelling of the world\n","2  en_US    this is the wrong spinal of the world"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["we see that the en_IN and en_UK models give us the expected answer"],"metadata":{"id":"Bzzmi4wfGEbq"}},{"cell_type":"code","source":["sent2 = \"this is ornage color\"\n","d2 = collections.defaultdict(list)\n","for corr in correctors:\n","  d2['tag'].append(corr.tag)\n","  d2['correction'].append(corr.return_best_sentence(sent2)[0])\n","\n","print(\"incorrect sentence: \", sent2)\n","pd.DataFrame(d2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161},"id":"DuPWtU_AGMdH","executionInfo":{"status":"ok","timestamp":1645261947991,"user_tz":-330,"elapsed":358,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"c70cb533-5a6d-4d64-f382-214f652e99d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["incorrect sentence:  this is ornage color\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-39477c20-1448-4cf4-87cd-523d0fc739c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tag</th>\n","      <th>correction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>en_IN</td>\n","      <td>this is orange colour</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>en_UK</td>\n","      <td>this is orange colour</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>en_US</td>\n","      <td>this is orange color</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39477c20-1448-4cf4-87cd-523d0fc739c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-39477c20-1448-4cf4-87cd-523d0fc739c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-39477c20-1448-4cf4-87cd-523d0fc739c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     tag             correction\n","0  en_IN  this is orange colour\n","1  en_UK  this is orange colour\n","2  en_US   this is orange color"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["\"color\" / \"colour\" correction is seen differently among these dictionaries"],"metadata":{"id":"Px9s3GhjHpOv"}},{"cell_type":"markdown","source":["____________________________________________"],"metadata":{"id":"oGNfJf-DKoR0"}},{"cell_type":"markdown","source":["# Context Based Grammar Checker\n","- Aim: to use ngram language model to correct contextually unlikely occuring sentences into more probable ones, thus capturing errors, both real word and non word errors.\n","- Let's use the previous SentenceCorrector class and use the unmasker bert mlm to get the word with highest score to correct the sentence"],"metadata":{"id":"kI7xjLMwKdlU"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install nltk "],"metadata":{"id":"nTvOptCgKnLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('words')\n","\n","from nltk.corpus import words\n","\n","words = words.words()"],"metadata":{"id":"RtDepHiIKzWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645261571121,"user_tz":-330,"elapsed":325,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"d618c50c-df08-42d6-c790-6c79475c482a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","unmasker = pipeline('fill-mask', model='bert-base-uncased')"],"metadata":{"id":"vyXPZeFmLKdr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Outputs\n","- We see the hybrid model of bert mlm and noisy channel sentence correction can yield better results with more accurate words."],"metadata":{"id":"i3oiCKfbUYO_"}},{"cell_type":"markdown","source":["Example:    \"he might tries to run\" \n","\n","Expected -> \"he might try to run\""],"metadata":{"id":"LDQPcGjOUtpN"}},{"cell_type":"code","source":["print(\"Masked Sentence: he might [MASK] to run\")\n","pd.DataFrame(unmasker('he might [MASK] to run'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"17wOnK24MWvN","executionInfo":{"status":"ok","timestamp":1645262009200,"user_tz":-330,"elapsed":353,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"3beb810f-1727-4b52-9748-a685781acd64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Masked Sentence: he might [MASK] to run\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-2ee7f361-7db4-4d98-927a-1938e4c05077\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>token</th>\n","      <th>token_str</th>\n","      <th>sequence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.705319</td>\n","      <td>2031</td>\n","      <td>have</td>\n","      <td>he might have to run</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.098274</td>\n","      <td>2215</td>\n","      <td>want</td>\n","      <td>he might want to run</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.097698</td>\n","      <td>2342</td>\n","      <td>need</td>\n","      <td>he might need to run</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.064293</td>\n","      <td>3046</td>\n","      <td>try</td>\n","      <td>he might try to run</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.007110</td>\n","      <td>2707</td>\n","      <td>start</td>\n","      <td>he might start to run</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee7f361-7db4-4d98-927a-1938e4c05077')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2ee7f361-7db4-4d98-927a-1938e4c05077 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2ee7f361-7db4-4d98-927a-1938e4c05077');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      score  token token_str               sequence\n","0  0.705319   2031      have   he might have to run\n","1  0.098274   2215      want   he might want to run\n","2  0.097698   2342      need   he might need to run\n","3  0.064293   3046       try    he might try to run\n","4  0.007110   2707     start  he might start to run"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["print(\"incorrect sentence: he might tries to run\")\n","print(\"corrected: \", corrector.return_best_sentence('he might tries to run')[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t-ZR5jiJU84s","executionInfo":{"status":"ok","timestamp":1645262169477,"user_tz":-330,"elapsed":341,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"9bb61e22-b13b-4e0e-9a2e-4449e7a6a0d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["incorrect sentence: he might tries to run\n","corrected:  he might tries to run\n"]}]},{"cell_type":"markdown","source":["We see that the noisy channel model alone fails to correct this error but with the help of candidate words from the Masked model, we can combine the 2 to generate better predictions."],"metadata":{"id":"j0u1TJXsVDZb"}},{"cell_type":"code","source":["corrector.candidate_word('tries')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLY1oofQbWtu","executionInfo":{"status":"ok","timestamp":1645261624986,"user_tz":-330,"elapsed":355,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"a0bad01f-52db-4287-ff02-e8161e44283f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['tires', 'tries', 'tories', 'triers'], 4)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["pd.DataFrame(unmasker('he will [MASK] a paella'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mi3Dd4EEdIq1","executionInfo":{"status":"ok","timestamp":1645261631115,"user_tz":-330,"elapsed":339,"user":{"displayName":"Gautham YS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghx-MRrDl7Fvlm9YB6fQsYK3NAjM7edicp8TL6WQw=s64","userId":"01533295209563733928"}},"outputId":"8b92381b-529b-4ecc-d8f6-66cec43e95aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-68d5a01c-026e-4129-aeb8-297e3184f221\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>score</th>\n","      <th>token</th>\n","      <th>token_str</th>\n","      <th>sequence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.261590</td>\n","      <td>2022</td>\n","      <td>be</td>\n","      <td>he will be a paella</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.112422</td>\n","      <td>2031</td>\n","      <td>have</td>\n","      <td>he will have a paella</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.096517</td>\n","      <td>2468</td>\n","      <td>become</td>\n","      <td>he will become a paella</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.073602</td>\n","      <td>4929</td>\n","      <td>wear</td>\n","      <td>he will wear a paella</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.032077</td>\n","      <td>2191</td>\n","      <td>make</td>\n","      <td>he will make a paella</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68d5a01c-026e-4129-aeb8-297e3184f221')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-68d5a01c-026e-4129-aeb8-297e3184f221 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-68d5a01c-026e-4129-aeb8-297e3184f221');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      score  token token_str                 sequence\n","0  0.261590   2022        be      he will be a paella\n","1  0.112422   2031      have    he will have a paella\n","2  0.096517   2468    become  he will become a paella\n","3  0.073602   4929      wear    he will wear a paella\n","4  0.032077   2191      make    he will make a paella"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# Downfalls\n","- Needs better correction of misplaced words and word variations, \n","- Eg. he be will makes food -> he will ~be~ ~makes~ make food "],"metadata":{"id":"7wxZulTteB8m"}}]}
